{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import get_yahoo_events\n",
    "from Personalized_News_Recommendation.dataset import get_yahoo_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4681992 events with 50 articles\n"
     ]
    }
   ],
   "source": [
    "file = f\"../../data/R6/ydata-fp-td-clicks-v1_0.20090501\"\n",
    "articles ,features, events = get_yahoo_events(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1241160900', '109513', '0', '|user', '2:0.000012', '3:0.000000', '4:0.000006', '5:0.000023', '6:0.999958', '1:1.000000', '|109498', '2:0.306008', '3:0.000450', '4:0.077048', '5:0.230439', '6:0.386055', '1:1.000000', '|109509', '2:0.306008', '3:0.000450', '4:0.077048', '5:0.230439', '6:0.386055', '1:1.000000', '|109508', '2:0.264355', '3:0.000012', '4:0.037393', '5:0.420649', '6:0.277591', '1:1.000000', '|109473', '2:0.295442', '3:0.000014', '4:0.135191', '5:0.292304', '6:0.277050', '1:1.000000', '|109503', '2:0.306008', '3:0.000450', '4:0.077048', '5:0.230439', '6:0.386055', '1:1.000000', '|109502', '2:0.277121', '3:0.000131', '4:0.038153', '5:0.335835', '6:0.348760', '1:1.000000', '|109501', '2:0.249086', '3:0.001009', '4:0.514682', '5:0.067732', '6:0.167491', '1:1.000000', '|109492', '2:0.331830', '3:0.000022', '4:0.019904', '5:0.440390', '6:0.207855', '1:1.000000', '|109495', '2:0.313277', '3:0.000125', '4:0.018413', '5:0.410555', '6:0.257630', '1:1.000000', '|109494', '2:0.306008', '3:0.000450', '4:0.077048', '5:0.230439', '6:0.386055', '1:1.000000', '|109484', '2:0.438513', '3:0.000003', '4:0.030714', '5:0.384494', '6:0.146277', '1:1.000000', '|109506', '2:0.264355', '3:0.000012', '4:0.037393', '5:0.420649', '6:0.277591', '1:1.000000', '|109510', '2:0.287909', '3:0.000025', '4:0.008983', '5:0.511333', '6:0.191751', '1:1.000000', '|109514', '2:0.297750', '3:0.000013', '4:0.011603', '5:0.512182', '6:0.178452', '1:1.000000', '|109505', '2:0.375829', '3:0.000025', '4:0.033041', '5:0.349637', '6:0.241468', '1:1.000000', '|109515', '2:0.281649', '3:0.000173', '4:0.195994', '5:0.151003', '6:0.371182', '1:1.000000', '|109512', '2:0.297322', '3:0.000025', '4:0.034951', '5:0.413566', '6:0.254137', '1:1.000000', '|109513', '2:0.211406', '3:0.000036', '4:0.002773', '5:0.569886', '6:0.215900', '1:1.000000', '|109511', '2:0.381149', '3:0.000129', '4:0.060038', '5:0.269129', '6:0.289554', '1:1.000000', '|109453', '2:0.421669', '3:0.000011', '4:0.010902', '5:0.309585', '6:0.257833', '1:1.000000']\n"
     ]
    }
   ],
   "source": [
    "import fileinput,re\n",
    "\n",
    "pattern =  r'\\|(\\d{6})'\n",
    "filenames = f\"../../data/R6/ydata-fp-td-clicks-v1_0.20090501\"\n",
    "\n",
    "with fileinput.input(files=filenames) as f:\n",
    "    for line in f:\n",
    "        cols = line.split()\n",
    "        # cols = line\n",
    "        # matches = re.findall(pattern, cols)\n",
    "        # print(matches)\n",
    "        print(cols)\n",
    "        break\n",
    "        # if (len(cols) - 10) % 7 != 0:\n",
    "        #     print(cols)\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = f\"../../data/R6/ydata-fp-td-clicks-v1_0.20090501\"\n",
    "\n",
    "def transform(filenames,path=\"./\"):\n",
    "\n",
    "    pattern =  r'\\|(\\d{6})'\n",
    "    article_ids = []\n",
    "    num_rows = 0\n",
    "\n",
    "    with open(path+'log_file.txt',\"a\",encoding=\"utf-8\") as log_file,open(path+'article_file.txt',\"a\",encoding=\"utf-8\") as article_file:\n",
    "\n",
    "        with fileinput.input(files=filenames) as f:\n",
    "            for line in f:\n",
    "                cols = line.split()[:10]\n",
    "                cols_raw = line\n",
    "                pools_idx = re.findall(pattern,cols_raw)\n",
    "                idx = cols[0]\n",
    "                article = cols[1]\n",
    "                r = cols[2]\n",
    "                feature = []\n",
    "                for x in cols[4:10]:\n",
    "                    feature.append(float(x[2:]))\n",
    "                out1 = str(idx)+' '+\" \".join(map(str,feature))+' '+str(article)+' '+str(r)+' '+\" \".join(pools_idx)\n",
    "                if article not in article_ids:\n",
    "                    article_ids.append(article)\n",
    "                    out2 = str(article)+' '+\" \".join(map(str,feature))\n",
    "                    article_file.write(out2+'\\n')\n",
    "                num_rows += 1\n",
    "                log_file.write(out1+'\\n')\n",
    "            print(f'{str(log_file)}和{str(article_file)}已经写完!')\n",
    "            print(f\"共有{len(article_ids)}篇文章，共有{num_rows}条数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='./log_file.txt' mode='a' encoding='utf-8'>和<_io.TextIOWrapper name='./article_file.txt' mode='a' encoding='utf-8'>已经写完!\n",
      "共有50篇文章，共有4681992条数据\n"
     ]
    }
   ],
   "source": [
    "transform(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = f\"../../data/R6/ydata-fp-td-clicks-v1_0.20090501\"\n",
    "\n",
    "def transform(filenames,path=\"./\"):\n",
    "\n",
    "    pattern =  r'\\|(\\d{6})'\n",
    "    article_ids = []\n",
    "    num_rows = 0\n",
    "\n",
    "    with open(path+'log_file.txt',\"a\",encoding=\"utf-8\") as log_file,open(path+'article_file.txt',\"a\",encoding=\"utf-8\") as article_file:\n",
    "\n",
    "        with fileinput.input(files=filenames) as f:\n",
    "            for line in f:\n",
    "                cols = line.split()[:10]\n",
    "                cols_raw = line\n",
    "                pools_idx = re.findall(pattern,cols_raw)\n",
    "                # idx = cols[0]\n",
    "                article = cols[1]\n",
    "                # r = cols[2]\n",
    "                # feature = []\n",
    "                # for x in cols[4:10]:\n",
    "                #     feature.append(float(x[2:]))\n",
    "                # out1 = str(idx)+' '+\" \".join(map(str,feature))+' '+str(article)+' '+str(r)+' '+\" \".join(pools_idx)\n",
    "                if article not in article_ids:\n",
    "                    article_ids.append(article)\n",
    "                    for a in pools_idx:\n",
    "                        if a not in article_ids:\n",
    "                            article_ids.append(a)\n",
    "    return len(article_ids),article_ids\n",
    "            #         article_ids.append(article)\n",
    "            #         out2 = str(article)+' '+\" \".join(map(str,feature))\n",
    "            #         article_file.write(out2+'\\n')\n",
    "            #     num_rows += 1\n",
    "            #     log_file.write(out1+'\\n')\n",
    "            # print(f'{str(log_file)}和{str(article_file)}已经写完!')\n",
    "            # print(f\"共有{len(article_ids)}篇文章，共有{num_rows}条数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,article_ids = transform(filenames,path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
